<p align="center">

<img src="./DeepSpeed-SFT/assets/image/ds-shiba.png" alt="DeepSpeed Shiba Inu!"/>

</p>

<div align="center">

## DeepSpeed åˆ†å¸ƒå¼å¾®è°ƒå®æˆ˜ï¼šå¤§æ¨¡å‹åŠ é€Ÿè®­ç»ƒæ–¹æ¡ˆä»¥åŠVLLMå®ç°æ¨¡å‹åŠ é€Ÿæ¨ç†

</div>

## ğŸš€ ä»‹ç»
æœ¬é¡¹ç›®åŸºäº LLaMA3.1-8B-Chinese å¼€æºåŸºåº§æ¨¡å‹ï¼Œæ‰€ç”¨çš„GPUæ˜¯4å—NVIDIA RTX A6000ï¼Œèšç„¦åŒ»å­¦é—®ç­”ä»»åŠ¡ï¼Œè®¾è®¡å¹¶å®ç°äº†ä¸€å¥—å¤§æ¨¡å‹é¢†åŸŸåŒ–å¾®è°ƒä¸éƒ¨ç½²æµç¨‹ã€‚é€šè¿‡ç»“åˆDeepSpeedåˆ†å¸ƒå¼è®­ç»ƒã€LoRAå¾®è°ƒã€VLLMå®ç°é«˜å¹¶å‘æ¨ç†åœ¨çº¿æœåŠ¡ç«¯æ­å»ºã€é‡åŒ–å‹ç¼©ã€RAG æ£€ç´¢å¢å¼º ç­‰å‰æ²¿æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡æ¨¡å‹åœ¨ä¸“ä¸šåŒ»å­¦é—®é¢˜ä¸Šçš„å›ç­”å‡†ç¡®ç‡ä¸ä¸“ä¸šåº¦ï¼ŒåŒæ—¶å¤§å¹…é™ä½æ¨ç†æˆæœ¬ã€‚å› ä¸ºè¿™ä¸ªæ˜¯æˆ‘åœ¨å­¦ä¹ å¤§æ¨¡å‹æ—¶çš„é¡¹ç›®ï¼Œå¯èƒ½æœ‰ä¸€äº›é—®é¢˜ï¼Œæ¬¢è¿æissueï¼Œå¸Œæœ›èƒ½å¯¹å¤§å®¶å­¦ä¹ å¤§æ¨¡å‹æœ‰å¸®åŠ©ã€‚
## ğŸ”¥ åŸºäºDeepSpeedçš„LoRAå¾®è°ƒ

### ğŸ¼ å®‰è£…ä¾èµ–
```bash
git clone https://github.com/RyanZxucheng/deepspeed-sft.git
cd DeepSpeed-SFT
pip install -r requirements.txt
```
å¦‚æœæœåŠ¡å™¨ä¸Šæ— æ³•è¿æ¥huggingfaceceï¼Œå¯ä»¥ç”¨æ¸…åé•œåƒæº
```bash
export HF_ENDPOINT=https://hf-mirror.com
```
## ğŸ• Step 1 - æœ‰ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰
###  å¯åŠ¨è®­ç»ƒ
```bash
cd training/supervised_finetuning/training_scripts/other_language
bash run_chinese.sh ./output  #./outputè¿™ä¸ªå‚æ•°å¯ä»¥è‡ªå·±çš„æ¢æˆè¾“å‡ºç›®å½•
```

## ğŸ• Step 2 - åŸºäºäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰
RLHF æ˜¯ä¸€ç§è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºè®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç”Ÿæˆå†…å®¹æ—¶æ›´ç¬¦åˆäººç±»æœŸæœ›ã€‚å®ƒç»“åˆäº† å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ å’Œ äººç±»åé¦ˆï¼ˆHFï¼‰ï¼Œä¸æ˜¯å•çº¯é é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè€Œæ˜¯è®©æ¨¡å‹å­¦ä¼šâ€œä»€ä¹ˆæ˜¯å¥½çš„å›ç­”â€ã€‚ç°æœ‰RLHFç®—æ³•æœ‰ï¼šPPOï¼ŒGRPOï¼ŒDPOï¼Œæˆ‘ä»¬è¿™é‡Œç”¨çš„æ˜¯DPOã€‚
###  å¯åŠ¨è®­ç»ƒ
```bash
cd training/dpo_finetuning/training_scripts/llama3
bash run_llama3_7b_lora.sh ./output  #./outputè¿™ä¸ªå‚æ•°å¯ä»¥è‡ªå·±çš„æ¢æˆè¾“å‡ºç›®å½•
```

###  å¦‚ä½•ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†
é™¤äº†ç¤ºä¾‹è„šæœ¬ä¸­ä½¿ç”¨çš„æ•°æ®é›†ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥æ·»åŠ å’Œä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œé¦–å…ˆéœ€è¦åœ¨[dschat/utils/data/raw_datasets.py](https://github.com/RyanZxucheng/deepspeed-sft/blob/main/DeepSpeed-SFT/dschat/utils/data/raw_datasets.py) ä¸­æ·»åŠ ä¸€ä¸ªæ–°ç±»æ¥å®šä¹‰ä½¿ç”¨æ•°æ®æ—¶çš„æ ¼å¼ã€‚éœ€è¦ç¡®ä¿éµå¾ªåœ¨PromptRawDatasetç±»ä¸­å®šä¹‰çš„apiå’Œæ ¼å¼ï¼Œä»¥ç¡®ä¿DeepSpeedæ‰€ä¾èµ–çš„æ•°æ®æ ¼å¼ä¸€è‡´ã€‚å¯ä»¥æŸ¥çœ‹ç°æœ‰çš„ç±»æ¥äº†è§£å¦‚ä½•åšã€‚

å…¶æ¬¡ï¼Œéœ€è¦åœ¨[dschat/utils/data/data_utils.py](https://github.com/RyanZxucheng/deepspeed-sft/blob/main/DeepSpeed-SFT/dschat/utils/data/data_utils.py)
ä¸­çš„get_raw_datasetå‡½æ•°ä¸­æ·»åŠ ä¸æ–°æ•°æ®é›†å¯¹åº”çš„ifæ¡ä»¶ã€‚ifæ¡ä»¶ä¸­çš„dataset_nameå­—ç¬¦ä¸²åº”è¯¥æ˜¯æ‚¨å°†ä½œä¸ºè®­ç»ƒè„šæœ¬å‚æ•°æä¾›çš„æ•°æ®é›†åç§°ã€‚æœ€åï¼Œéœ€è¦ä¿®æ”¹è®­ç»ƒè„šæœ¬ä¸­çš„â€œ--data_pathâ€å‚æ•°ä¸­ã€‚

###  æµ‹è¯•

```
export CUDA_VISIBLE_DEVICES=0
python prompt_eval.py \
--model_name_or_path_baseline XXX \
--model_name_or_path_finetune XXX
```
åˆ†åˆ«æ”¹æˆä½ çš„åŸºåº§æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹çš„è·¯å¾„,å¦‚æœæƒ³è¦ç›´æ¥å…ˆæµ‹è¯•ä¸€ä¸‹æ¨¡å‹æ•ˆæœï¼Œæˆ‘å·²ç»å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¸Šä¼ åˆ°[HuggingFace](https://huggingface.co/Ryyyyyyyan/Llama3.1-8B-Chinese-sft-medical)ä¸Šï¼Œæˆ–è€…ç›´æ¥å°†--model_name_or_path_finetuneå‚æ•°æ”¹ä¸ºRyyyyyyyan/Llama3.1-8B-Chinese-sft-medical
```
export CUDA_VISIBLE_DEVICES=0
python prompt_eval.py \
--model_name_or_path_baseline XXX \
--model_name_or_path_finetune Ryyyyyyyan/Llama3.1-8B-Chinese-sft-medical
```
## ğŸ”¥ VLLMé«˜å¹¶å‘æ¨ç†æœåŠ¡
### ğŸš€ ä»‹ç»
æœ¬é¡¹ç›®åŸºäº vLLM é«˜æ€§èƒ½æ¨ç†æ¡†æ¶ï¼Œå……åˆ†åˆ©ç”¨å…¶ Continuous Batching æœºåˆ¶ï¼Œå®ç°å¯¹æµ·é‡å¹¶å‘è¯·æ±‚çš„é«˜ååæ‰¹é‡æ¨ç†èƒ½åŠ›ã€‚ç³»ç»Ÿæ¶æ„é‡‡ç”¨ uvicorn + FastAPI æ„å»ºå¼‚æ­¥ HTTP æœåŠ¡ï¼Œä¸»çº¿ç¨‹é€šè¿‡ asyncio å°†ç”¨æˆ·è¯·æ±‚æäº¤è‡³ vLLM æ¨ç†é˜Ÿåˆ—ï¼Œç”±ç‹¬ç«‹æ¨ç†çº¿ç¨‹å®ŒæˆåŠ¨æ€åˆæ‰¹è®¡ç®—ï¼Œå¹¶å¼‚æ­¥è¿”å›ç»“æœã€‚

åŒæ—¶ï¼Œé¡¹ç›®æ”¯æŒ æµå¼æ¨ç†è¾“å‡ºï¼švLLM åŸç”Ÿæä¾›é€ token ç”Ÿæˆèƒ½åŠ›ï¼Œç»“åˆ FastAPI å¯å®ç°æŒ‰ chunk çš„æµå¼å“åº”ï¼Œå®¢æˆ·ç«¯å¯é€šè¿‡ requests ç­‰åº“é€æ­¥æ¥æ”¶å¹¶å®æ—¶å±•ç¤ºç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œå¸¦æ¥ä½å»¶è¿Ÿã€é¡ºæ»‘çš„äº¤äº’ä½“éªŒã€‚
### ğŸ¼ å®‰è£…ä¾èµ–
```bash
cd VLLM-server
pip install -r requirements.txt
```
###  åœ¨çº¿æ¨ç†æœåŠ¡
å¯åŠ¨é«˜å¹¶å‘åœ¨çº¿æ¨ç†æœåŠ¡
```bash
python vllm_server_llama.py
```
å¯åŠ¨httpå®¢æˆ·ç«¯æ¥è®¿é—®ä¹‹å‰éƒ¨ç½²å¥½çš„æ¨ç†æœåŠ¡
```bash
python vllm_client.py
```
è¿™æ ·ä½ å°±å¯ä»¥å¯¹ä¹‹å‰éƒ¨ç½²å¥½çš„æ¨¡å‹è¿›è¡Œè°ƒç”¨ï¼Œå¹¶ä¸”å¯ä»¥æµå¼è¿”å›æ¨ç†ç»“æœ
## ğŸ”¥ åŸºäºllama.cppçš„é‡åŒ–
### ğŸ¼ å®‰è£…ä¾èµ–
ç®€æ˜“æ•™ç¨‹ï¼Œå¦‚æœæœ‰ä¸æ‡‚çš„ä¹Ÿå¯å‚è€ƒå®˜æ–¹å®Œæ•´çš„llama.cpp[ç¼–è¯‘æ•™ç¨‹](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md)
é¦–å…ˆè·å¾—åŸé¡¹ç›®
```bash
git clone https://github.com/ggml-org/llama.cpp.git
cd llama.cpp
```
å®‰è£…ç›¸å…³ä¾èµ–ä»¥åŠç¼–è¯‘é¡¹ç›®
```bash
pip install -r requirements/requirements-convert_hf_to_gguf.txt
cmake -B build
cmake --build build --config Release
```
è¦ç”¨llama.cppé‡åŒ–æ¨¡å‹éœ€è¦å…ˆè½¬æ¢æˆggufæ ¼å¼ï¼Œåˆ©ç”¨é¡¹ç›®ä¸­çš„convert_hf_to_gguf.pyè„šæœ¬
```bash
convert_hf_to_gguf.py XXX --outtype f16 --outfile YYY.gguf
```
XXXä¸ºä½ å¾®è°ƒçš„æ¨¡å‹åœ°å€ï¼ŒYYYæ˜¯è¾“å‡ºæ–‡ä»¶çš„åœ°å€
ä¹‹åå°±å¯ä»¥ç›´æ¥é‡åŒ–ï¼Œä½¿ç”¨ build/bin/Release/quantize.exeæ¥è¿›è¡Œé‡åŒ–
```bash
quantize.exe YYY.gguf quantized_model.gguf q4_0
```
å‰é¢æ˜¯åˆšåˆšè½¬æ¢çš„ggufæ ¼å¼æ–‡ä»¶ï¼Œåé¢æ˜¯è‡ªå·±å‘½åçš„é‡åŒ–æ–‡ä»¶,æœ€åæ˜¯çš„ç‰ˆæœ¬é‡åŒ–ï¼Œå¯å»å®˜æ–¹æŸ¥çœ‹æœ‰å“ªäº›å‚æ•°ï¼Œæˆ‘è‡ªå·±çš„é‡åŒ–ç‰ˆæœ¬å·²ä¸Šä¼ è‡³HuggingFaceï¼Œæ„Ÿå…´è¶£çš„å°ä¼™ä¼´å¯è‡ªè¡Œ[ä¸‹è½½](https://huggingface.co/Ryyyyyyyan/Llama3.1-8B-Chinese-sft-medical-Q4_K_M-GGUF):
```bash
https://huggingface.co/Ryyyyyyyan/Llama3.1-8B-Chinese-sft-medical-Q4_K_M-GGUF
```



